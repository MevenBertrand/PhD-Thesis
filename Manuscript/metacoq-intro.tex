\kl{Coq} is a very complex tool. Even its \kl{kernel}, which is only but a very small
fraction of the tool, is already quite complex, relying on subtle implicit invariants which
might not be properly maintained, especially when the code evolves.
In practice, around one critical bug is found every year.%
\sidenote{A \href{https://github.com/coq/coq/blob/master/dev/doc/critical-bugs}{compilation}
  of those is maintained by \kl{Coq}’s development team.}
Although it is not easy to exploit these to actually derive an inconsistency, even less
so inadvertedly, simply relying on the \kl{De Bruijn criterion} is not enough if
one wants to have a maximal trust in the kernel – and thus \kl{Coq} as a whole.
Although \kl{CIC} is well-understood and has been widely studied,
this is much less true of the type theory which is actually implemented, \kl{PCUIC}.
This is why bugs usually creep in with the extra level of complexity added by \kl{PCUIC},
which is rarely handled in details on paper proofs.%
\sidenote{This is for instance the case of the completeness issue
  explained in \cref{sec:bidir-pcuic-inductives}.}

This all begs for a precise investigation of \kl{PCUIC}, from the subtleties of the
type system’s meta-theory, all the way down to the sophisticated details of the implementation.
Due to the level of complexity of the endeavour, it is not feasible on paper. Nor is it
desirable: if in the end we wish to write down a certified kernel, it is natural to do so
in a proof assistant, so that we can run that certified implementation.
Instead, the natural framework is the \kl{MetaCoq} project,
which aims at giving tools to reify and manipulate \kl{Coq} terms%
\sidenote{Or, maybe more accurately, \kl{Gallina}.}
inside of \kl{Coq} itself. This gives the possibility to write down and certify
all kinds of procedures operating on these terms – the first to come to mind being of course
a type-checker. This way, we can have both the help and guarantees offered by
formal proofs inside a \kl{proof assistant}, and the possibility to execute
our implemented kernel.

There are two important caveats to this, though.
The first pertains to Gödel’s second incompleteness
theorem. Because of it, it is impossible to prove \kl{Coq}’s consistency inside \kl{Coq} itself,
meaning that the meta-theoretical study can only be partial, since otherwise it would allow
a proof of consistency contradicting Gödel’s theorem. Indeed, \kl{MetaCoq} relies on a single
axiom, asserting the \kl{normalization} of \kl{PCUIC},
which is the blind spot we must allow in order to circumvent this limitation.
A second is that writing down a certified kernel is not enough. Indeed, executing directly
such a kernel in \kl{Coq} would be much too slow to actually be able to type-check
any reasonable term. Rather, we must rely on extraction, a procedure which erases the
proof-related content of a certified program to only keep the algorithmically relevant one.
As this erasure itself is a complex transformation, \kl{MetaCoq} also incorporates a certified
erasure procedure.

In this part, I shall describe the portion of \kl{MetaCoq} which is relevant to the thesis.
\Cref{chap:metacoq-general} gives a general overview of the meta-theoretical study of \kl{PCUIC},
with the main definitions and properties.
My technical contributions to this part of the development is relatively minor,
mainly consisting of small patches. However, since I reuse quite a lot of those properties
in my main contributions, it seems fitting to at least say a word on it.
\Cref{chap:kernel-correctness} concentrates on the formalization of bidirectional typing, as
presented in \arefpart{bidir}, and on the proof of correctness and completeness of
the kernel implementation based on it. It contains my main technical
contributions to the \kl{MetaCoq} project.

Throughout the part, source files of the \kl{MetaCoq} project
and specific definitions or theorems are referenced respectively as follows:
\pcuicfile{Typing}, and \pcuicline{Typing}{typing}{188}. They link directly to the source
code of the project on \kl{GitHub}.
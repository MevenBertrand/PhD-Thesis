\chapter{Warm-up: CCω}
\label{chap:bidir-ccw}

\margintoc

% In this chapter, we give an alternate presentation of \kl{CCω}, as defined in
% \cref{fig:ccw-typing}. Most of the ideas are abstract over the notion of \kl{conversion}
% that is considered,
% so either \kl(conv){declarative} or \kl(conv){algorithmic} conversion can be used without
% much impact.

\section{Turning \kl{CCω} Bidirectional}
\label{sec:bidir-ccw}

\subsection{McBride’s discipline}

To design our bidirectional type system, we follow a discipline exposed by McBride
\sidecite{McBride2018,McBride2019}.
The central point is to distinguish in a judgement between the \intro{subject},
whose well-formedness is under scrutiny, \intro{inputs},
whose well-formedness is a condition for it to be meaningful,
and \intro{outputs}, whose well-formedness is a consequence of it.
We use the word \intro{well-formed} in a generic way for contexts, terms and types,
it stands for:
\begin{itemize}
  \item $\vdash \Gamma$ in the case of a context $\Gamma$,
  \item $\Gamma \vdash T : \uni$ in the case of a type $T$,
  \item the existence of some $T$ such that $\Gamma \vdash t \ty T$ in the case of a term $t$.
\end{itemize}
We also use \intro{well-typed} for a term, with the same meaning as \intro{well-formed}.

For instance, in the case of inference $\inferty{\Gamma}{t}{T}$, the subject is $t$,
$\Gamma$ is an input and $T$ is an output.
This means that one should consider whether $\inferty{\Gamma}{t}{T}$
only in cases where $\vdash \Gamma$ is already known,
and if the judgement is derivable it should be possible to conclude that
not only $t$, but also $T$ are well-formed.

In order to enforce this property globally, all inference rules should locally
preserve it as an invariant.%
\sidenote{The motto – slightly adapted from \textcite{McBride2018} – is:
  \textit{A rule is a server for its conclusion and a client for its premises.
  Servers receive promises about inputs and make promises about outputs, clients make
  promises about inputs and receive promises about outputs.}}
More precisely, information flows in a clockwise manner. First, one can assume that inputs
to the conclusion are well-formed – they are inputs to the rule. Next, we move to the
premises. Here the constraint is reversed: we should ensure that inputs to the premises are
well-formed, but can assume that their outputs and subjects are. In particular,
the well-formedness of inputs to a premise can rely on that of subjects or outputs
of previous ones.
Finally, information goes to the conclusion again, and now not only the subject but also
the output should be well-formed if all those of the premises are.

This distinction also applies to computation-related judgements, although those have no subject – instead, what is under scrutiny is the computational context of the rule.
For conversion $\Gamma \vdash T \conv T' : \uni$, 
both $T$ and $T'$ are inputs and thus should be known to be well-formed beforehand.
For reduction $T \red T'$, on the contrary, $T$ is an input,
but $T'$ is an output. Hence, only $T$ needs to be well-formed \textit{a priori},
and we rely on the \kl{subject reduction} property to ensure
that the output $T'$ also is.

\subsection{Constrained inference}

Beyond the already mentioned inference and checking judgements,
we need to introduce a third one: \intro{constrained inference}, written
$\pinferty{h}{\Gamma}{t}{T}$, where $h$ is either $\Pi$ or $\uni$.%
\sidenote{This is because these are the only type formers in \kl{CCω}.
In \kl{PCUIC}, $h$ can also be \eg and inductive type.}
Constrained inference is a judgement – or, rather, a family of judgements indexed by $h$ –
with the exact same modes as inference, but where the type output is not completely free.
Rather, as the name suggests, a constraint is imposed on it, namely that its head constructor can only be the corresponding element of $h$.
This is needed to handle the behaviour absent in simple types that some terms might not have a desired type “on the nose”. Take for instance the first premise
$\Gamma \vdash t \ty \P x : A .\ B$ of \ruleref{rule:cic-app}.
What bidirectional judgement should replace it?
It would be too much to ask $t$ to directly infer a $\Pi$-type, as some reduction might be needed to uncover this $\Pi$. Checking also cannot be used, because the domain and codomain of the tentative $\Pi$-type are not known at that point: they are to be inferred from $t$.

\subsection{Structural rules}

To transform the rules of \kl{CCω} as given in \cref{fig:ccw-typing}, we start by recalling that we wish to obtain a complete bidirectional type system.
Therefore, any term should infer a type, and thus all structural rules –
\ie all rules where the subject of the conclusion starts with a term former –
should give rise to an inference rule.
It thus remains to choose the judgements for the premises, which amounts to determining their modes.
If a term in a premise appears as input in the conclusion or output of a previous premise, then it can be considered an input, otherwise it must be an output. Moreover, if a type output is unconstrained, then inference can be used, otherwise we must resort to constrained inference.

\begin{figure}[ht]
  \ContinuedFloat*
  \begin{mathpar}
    \inferdef{Var}
      {(x : T) \in \Gamma}
      {\inferty{\Gamma}{x}{T}}
    \label{rule:bd-var} \and
    \inferdef{Univ}
      { }
      {\inferty{\Gamma}{\uni[i]}{\uni[i+1]}}
    \label{rule:bd-univ} \and
    \inferdef{ΠTy}
      {\pinferty{\uni}{\Gamma}{A}{\uni[i]} \\
        \pinferty{\uni}{\Gamma, x : A}{B}{\uni[j]}}
      {\inferty{\Gamma}{\P x : A .\ B}{\uni[\umax{i}{j}]}}
    \label{rule:bd-prod} \and 
    \inferdef{Abs}
      {\pinferty{\uni}{\Gamma}{A}{\uni[i]} \\ \inferty{\Gamma, x : A}{t}{B}}
      {\inferty{\Gamma}{\l x : A .\ t}{\P x : A .\ B}}
    \label{rule:bd-abs} \and
    \inferdef{App}
      {\pinferty{\Pi}{\Gamma}{t}{\P x : A .\ B} \\ \checkty{\Gamma}{u}{A}}
      {\inferty{\Gamma}{t\ u}{\subs{B}{x}{u}}}
    \label{rule:bd-app} \\
  \end{mathpar}
  \caption{Rules for inference in bidirectional \kl{CCω}}
  \label{fig:ccw-bidir-infer}
\end{figure}

In anticipation, we set the typing rules for \kl{CCω} so that this transformation would be
directly applicable. This particularly applies to the undirected \ruleref{rule:cic-abs},
recalled opposite.
\marginnote{
  \normalsize
  \begin{mathpar}
  \inferrule*[vcenter,right=Abs]
  {\Gamma \vdash A \ty \uni \\ \Gamma, x : A \vdash t \ty B}
  {\Gamma \vdash \l x : A.\ t \ty \P x : A.\ B}
  \end{mathpar}
}
Indeed, there are at least two other ways to write this rule, which do not lead to a valid
bidirectional presentation.
The first, which is the usual one in \kl{PTS},
is to have $\Gamma \vdash \P x : A.\ B \ty \uni$ instead of simply $\Gamma \vdash A \ty \uni$.
In the setting of a general \kl{PTS}, this is needed, because not every Π-type is well-formed,
even if the domain and codomain are.%
\sidenote{\kl{PTS} where this is true are called \intro{full}.}
However, this premise is problematic in the bidirectional setting. Indeed, $B$ can only be
inferred as a type for the body of the abstraction $t$. But to infer a type for $t$, the
context $\Gamma, x : A$ needs to be well-formed, which is not know if this premise is
the first one.
This issue has been identified by \sidetextcite{Pollack1992}, who remarks that the
bidirectional structure we present here only is equivalent to the undirected one
in semi-full \kl{PTS} – a slight generalization of the full ones.
In a full \kl{PTS}, the opposite approach of simply removing the first premise altogether
can also be taken, relying on \kl{validity} to ensure that $\vdash \Gamma, x \ty A$ and thus
$\Gamma \vdash A : \uni$. But again, in a bidirectional setting,
this does not respect McBride’s discipline.

The main difference between the bidirectional and undirected rules is that we dropped
hypotheses of context well-formedness in Rules~\nameref{rule:bd-univ} and
\nameref{rule:bd-var}. Indeed, as the context is always supposed to be well-formed
as an input to the conclusion, it is not useful to re-check it. This is also in line with implementations, where the context is not re-checked at leaves of a derivation tree, with performance issues in mind. The well-formedness invariants then ensure that any derivation starting with the (well-formed) empty context will only ever encounter well-formed contexts.

\subsection{Computation rules}

\begin{marginfigure}
\ContinuedFloat
\begin{mathpar}
  \inferdef{Check}
    {\inferty{\Gamma}{t}{T'} \\ T' \conv T}
    {\checkty{\Gamma}{t}{T}}
  \label{rule:bd-check} \and
  \inferdef{Univ-Inf}
    {\inferty{\Gamma}{t}{T} \\ T \fred \uni[i]}
    {\pinferty{\uni}{\Gamma}{t}{\uni[i]}}
    \label{rule:bd-pinf-univ} \and
  \inferdef{Π-Inf}
    {\inferty{\Gamma}{t}{T} \\ T \fred \P x : A. B}
    {\pinferty{\P}{\Gamma}{t}{\P x : A . B}}
    \label{rule:bd-pinf-prod}
\end{mathpar}
\caption{Computation rules for bidirectional \kl{CCω}}
\end{marginfigure}

We are left with the only non-structural rule, \ruleref{rule:cic-conv}.
As we observed, there are two possible modes for premises of inference rules where some
constraint is present, leading to the use of either checking or constrained inference.
In turn, this leads to two different modes for computation.
If the target type is an input, it can be compared to the inferred one using \kl{conversion}.
But if it is unknown (constrained inference) we must resort to \kl{reduction},
and obtain it from the inferred one.
This eventually leads to the decomposition of \ruleref{rule:cic-conv} into
\ruleref{rule:bd-check} in the first case, while
\nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod} correspond to the second case.

Note that while the use of conversion and reduction have changed, those relations themselves
remain untouched. We only refined them by giving them an explicit mode.

\subsection{Constrained inference in disguise}

This need to split the conversion rule into a reduction and conversion sub-routine depending on the mode is of course known to the implementors of proof assistants \sidecite{Abel2011}.
It explains in part the ubiquity of \kl(red){weak-head} reduction
in the dependently typed setting.
Indeed, it is exactly the minimal reduction strategy that is needed to expose the
head constructor of a type, and thus to implement constrained inference.

Still, reduction is only a means to determine whether a certain term fits into a certain category of types. In the setting of \kl{CCω}, this is basically the only way to do.
However, as soon as conversion is extended,
% for instance with unification
% \sidecite{Asperti2012}, coercions \sidecite{Asperti2012,Sozeau2007}
% or graduality \sidecite{LennonBertrand2022},
reduction is often not enough any more.
Putting constrained inference forward explains some ideas required in those: 
they are not ad-hoc workaround, but are based on the need to account for constrained inference.

We already mentioned \sidetextcite{Pollack1992}, where $\Gamma \vdash t \ty T$ is used
for inference, and a judgement written $\Gamma \vdash t \mathrel{:\geq} T$ –
denoting type inference followed by reduction –
is used to effectively inline the two hypothesis of our constrained inference rules.
Checking is also inlined.
Similarly, \sidetextcite{Abel2008} use a judgement written $\Delta \vdash V \delta \Uparrow \operatorname{Set} \rightsquigarrow i$, where a type $V$ is checked to be well-formed, but with its exact level $i$ free. This corresponds very closely to our use of $\pity{\uni}$.

But the main area where constrained inference repeatedly becomes apparent is that of
elaboration. For instance,
\sidetextcite{Saibi1997} describes an elaboration mechanism inserting coercions between types.
This happens primarily during checking, when both types are known.
However, \citeauthor{Saibi1997} introduces two special classes to handle the need
to cast a term to a sort or a function type without more information,
exactly in the places where we resort to constrained inference instead of checking.
More recently, \sidetextcite{Sozeau2007} describes a system where conversion is augmented
to handle coercion between subset types.
As in \textcite{Pollack1992}, $\Gamma \vdash t \ty T$ is used for inference,
and the other judgements are inlined.
Once again, reduction is not enough to perform constrained inference, this time
because type constructors can be hidden in subsets:
a type such as $\{f : \Nat \to \Nat \mid f\ 0 = 0 \}$
should be usable as a function of type $\Nat \to \Nat$.
An erasure procedure is therefore required on top of reduction to remove subset types in the places where we use constrained inference.

Analogous ideas can also be found in \kl{Matita}'s elaboration algorithm, as described in 
\sidetextcite{Asperti2012}.
Indeed, the presence of unification meta-variables on top of coercions makes it
even clearer that specific treatment of what we identified as constrained inference is
required.
\citeauthor{Asperti2012} introduce a special judgement they call
type-level enforcing, which corresponds to our $\pity{\uni}$ judgement.
As for $\pity{\P}$, they have two rules to apply a function, one where its inferred type reduces to a Π-type, corresponding to \ruleref{rule:bd-pinf-prod}.
and another one to handle the case when the inferred type instead reduces to a meta-variable.
As \citeauthor{Saibi1997} and \citeauthor{Sozeau2007}, they also
need to handle coercions for terms in function position. However, their solution is different:
They introduce new meta-variables for the domain and codomain, and rely on unification, which is available in their setting, to find values for those.
For $\pity{\uni}$, though, this solution is not viable, as one would need a kind of universe
meta-variable. Instead, they rely on backtracking to test multiple possible universe choices.

Finally, in \arefpart{gradual}, somewhat akin to the use of meta-variables in
\textcite{Asperti2012}, there are two rules per constrained inference judgement.
One when the head constructor is the desired one – as for \kl{CCω} –,
and a second one to handle the wildcard $\?$, characteristic of gradual type systems.


\section{Properties of the Bidirectional System}
\label{sec:bidir-prop}

Let us now state and prove the main properties of the bidirectional system.
The first two relate the bidirectional system to the
undirected one: it is both \kl(bidir){correct} – terms typeable in the bidirectional system are typeable in the undirected system – and \kl(bidir){complete} – all terms typeable in the undirected system are also typeable in the bidirectional system.
Next, we investigate uniqueness of typing, and its relation to the choice of a strategy for reduction.
Finally, we show how strengthening can be shown for undirected \kl{CCω} by proving it on the
directed side.

\subsection{Correctness and completeness}

A bidirectional derivation can be seen as a refinement of an undirected derivation.
Indeed, the bidirectional structure can be erased
– replacing each bidirectional rule with the corresponding undirected rule – to obtain an undirected derivation. This is missing some sub-derivations of context well-formedness at
leaves of a derivation, or that of the target type for \ruleref{rule:cic-conv}.
These can nevertheless be retrieved by using the invariants
on well-formedness of inputs and outputs.
Thus, we get the following correctness theorem – note how McBride’s discipline manifests as well-formedness hypothesis on inputs.

\begin{theorem}[\intro{Correctness} of bidirectional typing for \kl{CCω}]
  \label{thm:corr-ccomega}
  If $\Gamma$ is well-formed and $\inferty{\Gamma}{t}{T}$ or $\pinferty{h}{\Gamma}{t}{T}$,
  then $\Gamma \vdash t \ty T$.
  If both $\Gamma$ and $T$ are well-formed and
  $\checkty{\Gamma}{t}{T}$, then $\Gamma \vdash t \ty T$. 
\end{theorem}
  
\begin{proof}
  The proof is by mutual induction on the bidirectional typing derivation.

  Each rule of the bidirectional system can be replaced by the corresponding rule of the
  undirected system, with all three Rules \nameref{rule:bd-check}, \nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod} replaced by
  \nameref{rule:cic-conv}. In all cases, the induction hypothesis can be used on sub-derivations of the bidirectional judgement, because context extensions and checking are
  done with types that are known to be well-formed,
  either by induction hypothesis on previous premises and \kl{validity}.%
  \sidenote{This is the point where following McBride’s discipline is crucial!}

  Some sub-derivations of the undirected rules that have no counterpart
  in the bidirectional ones are however missing.
  In Rules \nameref{rule:cic-univ} and \nameref{fig:cic-var},
  the hypothesis that $\Gamma$ is well-formed is enough to get the required premise.
  For \ruleref{rule:bd-check},
  the well-formedness hypothesis on the type is needed to get the typing premise of
  \nameref{rule:cic-conv-unty}.
  As for Rules \nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod},
  that typing premise is obtained by combining the induction hypothesis,
  validity and \kl{subject reduction}.

  Alternatively, usage of validity could be handled by
  strengthening the theorem to incorporate the well-formedness of outputs on top of that of
  the subject. But we follow the proofs in \kl{MetaCoq}, which establish
  meta-theoretical properties of the undirected system – including validity –,
  rather than those of the bidirectional one – such as stability by substitution.

\end{proof}

Contrarily to correctness, which keeps the structure of a derivation,
completeness is of a different nature.
Because in bidirectional derivations the computation rules are much less liberal than in
undirected derivations,
the crux of the proof is to ensure that all uses of \ruleref{rule:cic-conv}
can be permuted down through the other, structural, rules,
in order to concentrate them in the places where they are authorized in the bidirectional
derivation.
In a way, composing completeness with correctness gives a kind of normalization procedure
which produces a canonical undirected derivation by pushing conversion
down as much as possible.

The proof crucially relies on the following lemma,
which can be seen as a form of \kl{injectivity of type constructors} – which is a direct
consequence of it.

\begin{lemma}[Conversion implies reduction for type constructors]
  \label{lem:conv-red-tycons}
  If $T \conv \uni[i]$, then $T \red \uni[i]$.

  If $T \conv \P x : A.\ B$, then there exist $A'$ and $B'$ such that:
  \begin{itemize}
    \item $T \red \P x : A'.\ B'$
    \item $A' \conv A$
    \item $B' \conv B$
  \end{itemize}
\end{lemma}

\begin{proof}
  Let us spell out the proof on Π-types – the case of $\uni$ is similar, but easier.

  For \kl{algorithmic conversion}, by definition there must exist $T'$ and $T''$
  such that $T \red T'$, $\P x : A.\ B \red T''$, $T' \alpheq T''$.
  But there can be no \kl{top-level} reduction step in $\P x : A.\ B \red T''$, so actually
  $T''$ is some $\P x : A''.\ B''$ and $A \red A''$, $B \red B''$.
  Similarly, $T'$ must be some $\P x : A'.\ B'$
  such that $A' \alpheq A''$ and $B' \alpheq B''$.
  Combining these, we obtain that $A' \conv A$ and $B' \conv B$, as expected.

  For \kl{declarative conversion}, one can use the previous proof of
  equivalence with algorithmic conversion – and thus \kl{confluence}.
\end{proof}

\begin{theorem}[\intro{Completeness} of bidirectional typing for \kl{CCω}]
  \label{thm:compl-ccomega}
  If $\Gamma \vdash t \ty T$, then there exists $T'$ such that $\inferty{\Gamma}{t}{T'}$
  and $T' \conv T$.
\end{theorem}

\begin{proof}
  The proof is by induction on the undirected typing derivation.
  
  Rules \nameref{rule:cic-var} and \nameref{rule:cic-univ} are base cases,
  and can be simply replaced by the corresponding bidirectional rules.
  In the case of \ruleref{rule:cic-conv}, the property is a direct consequence of the induction hypothesis together with transitivity of conversion: we simply conflate two conversions
  together.
  
  As for \ruleref{rule:cic-prod}, the induction hypothesis on the domain $A$
  gives the existence of $T_A$
  such that $\inferty{\Gamma}{A}{T_A}$ and $T_A \conv \uni[i]$. Using
  \cref{lem:conv-red-tycons}, we can derive $\pinferty{\uni}{\Gamma}{A}{\uni[i]}$.
  Applying a similar reasoning on the codomain and combining both is enough to conclude.


  In \ruleref{rule:cic-abs}, we do the same reasoning again on the type annotation.
  Combined with the induction hypothesis on the body $t$,
  we get $\inferty{\Gamma}{\l x : A.\ t}{\P x : A .\ B'}$ for some $B'$ such that $B \conv B'$, and thus $\P x : A . B \conv \P x : A . B'$ as desired.

  We are finally left with \ruleref{rule:cic-app}.
  Again, the key is \cref{lem:conv-red-tycons}, which can be combined with the induction
  hypothesis on the function $f$ to get $\pinferty{\P}{\Gamma}{f}{\P x : A' .\ B'}$
  for some $A'$ and $B'$ such that $A \conv A'$ and $B \conv B'$ – where $\P x : A. B$ is
  the type for $f$ in the undirected derivation.
  The induction hypothesis on the argument $u$ gives
  $\inferty{\Gamma}{u}{A''}$ with $A'' \conv A$. Thus, by transitivity of conversion
  $\inferty{\Gamma}{u}{A'}$, and we can apply \ruleref{rule:bd-app} to conclude.

\end{proof}

Interestingly, the proof of correctness relies on \kl{subject reduction}, which itself
needs \kl{injectivity of type constructors} and \kl{transitivity} of conversion.
Similarly, completeness relies both on the injectivity as given by \cref{lem:conv-red-tycons},
and transitivity of conversion. Be it for algorithmic or declarative conversion, one at
least of those is not directly provable – we need \kl{confluence}.
We already hit this same tension with \kl{subject reduction}, and
must draw the same conclusion: there is no free lunch!

\subsection{Uniqueness and reduction strategies}


\subsection{Strengthening}
\chapter{Warm-up: CCω}
\label{chap:bidir-ccw}

\margintoc

% In this chapter, we give an alternate presentation of \kl{CCω}, as defined in
% \cref{fig:ccw-typing}. Most of the ideas are abstract over the notion of \kl{conversion}
% that is considered,
% so either \kl(conv){declarative} or \kl(conv){algorithmic} conversion can be used without
% much impact.

\section{Turning \kl{CCω} Bidirectional}
\label{sec:bidir-ccw}

\subsection{McBride’s discipline}

To design our bidirectional type system, we follow a discipline exposed by McBride
\sidecite{McBride2018,McBride2019}.
The central point is to distinguish in a judgement between the \intro{subject},
whose well-formedness is under scrutiny, \intro{inputs},
whose well-formedness is a condition for it to be meaningful,
and \intro{outputs}, whose well-formedness is a consequence of it.
We use the word \intro{well-formed} in a generic way for contexts, terms and types,
it stands for:
\begin{itemize}
  \item $\vdash \Gamma$ in the case of a context $\Gamma$,
  \item $\Gamma \vdash T : \uni$ in the case of a type $T$,
  \item the existence of some $T$ such that $\Gamma \vdash t \ty T$ in the case of a term $t$.
\end{itemize}
We also use \intro{well-typed} for a term, with the same meaning as \intro{well-formed}.

For instance, in the case of inference $\inferty{\Gamma}{t}{T}$, the subject is $t$,
$\Gamma$ is an input and $T$ is an output.
This means that one should consider whether $\inferty{\Gamma}{t}{T}$
only in cases where $\vdash \Gamma$ is already known,
and if the judgement is derivable it should be possible to conclude that
not only $t$, but also $T$ are well-formed.

In order to enforce this property globally, all inference rules should locally
preserve it as an invariant.%
\sidenote{The motto – slightly adapted from \textcite{McBride2018} – is:
  \textit{A rule is a server for its conclusion and a client for its premises.
  Servers receive promises about inputs and make promises about outputs, clients make
  promises about inputs and receive promises about outputs.}}
More precisely, information flows in a clockwise manner. First, one can assume that inputs
to the conclusion are well-formed – they are inputs to the rule. Next, we move to the
premises. Here the constraint is reversed: we should ensure that inputs to the premises are
well-formed, but can assume that their outputs and subjects are. In particular,
the well-formedness of inputs to a premise can rely on that of subjects or outputs
of previous ones.
Finally, information goes to the conclusion again, and now not only the subject but also
the output should be well-formed if all those of the premises are.

This distinction also applies to computation-related judgements, although those have no subject – instead, what is under scrutiny is the computational context of the rule.
For conversion $\Gamma \vdash T \conv T' : \uni$, 
both $T$ and $T'$ are inputs and thus should be known to be well-formed beforehand.
For reduction $T \red T'$, on the contrary, $T$ is an input,
but $T'$ is an output. Hence, only $T$ needs to be well-formed \textit{a priori},
and we rely on the \kl{subject reduction} property to ensure
that the output $T'$ also is.

\subsection{Constrained inference}

Beyond the already mentioned inference and checking judgements,
we need to introduce a third one: \intro{constrained inference}, written
$\pinferty{h}{\Gamma}{t}{T}$, where $h$ is either $\Pi$ or $\uni$.%
\sidenote{This is because these are the only type formers in \kl{CCω}.
In \kl{PCUIC}, $h$ can also be \eg and inductive type.}
Constrained inference is a judgement – or, rather, a family of judgements indexed by $h$ –
with the exact same modes as inference, but where the type output is not completely free.
Rather, as the name suggests, a constraint is imposed on it, namely that its head constructor can only be the corresponding element of $h$.
This is needed to handle the behaviour absent in simple types that some terms might not have a desired type “on the nose”. Take for instance the first premise
$\Gamma \vdash t \ty \P x : A .\ B$ of \ruleref{rule:cic-app}.
What bidirectional judgement should replace it?
It would be too much to ask $t$ to directly infer a $\Pi$-type, as some reduction might be needed to uncover this $\Pi$. Checking also cannot be used, because the domain and codomain of the tentative $\Pi$-type are not known at that point: they are to be inferred from $t$.

\subsection{Structural rules}

To transform the rules of \kl{CCω} as given in \cref{fig:ccw-typing}, we start by recalling that we wish to obtain a complete bidirectional type system.
Therefore, any term should infer a type, and thus all structural rules –
\ie all rules where the subject of the conclusion starts with a term former –
should give rise to an inference rule.
It thus remains to choose the judgements for the premises, which amounts to determining their modes.
If a term in a premise appears as input in the conclusion or output of a previous premise, then it can be considered an input, otherwise it must be an output. Moreover, if a type output is unconstrained, then inference can be used, otherwise we must resort to constrained inference.

\begin{figure}[ht]
  \ContinuedFloat*
  \begin{mathpar}
    \inferdef{Var}
      {(x : T) \in \Gamma}
      {\inferty{\Gamma}{x}{T}}
    \label{rule:inf-ccw-var} \and
    \inferdef{Sort}
      { }
      {\inferty{\Gamma}{\uni[i]}{\uni[i+1]}}
    \label{rule:inf-ccw-sort} \and
    \inferdef{Prod}
      {\pinferty{\uni}{\Gamma}{A}{\uni[i]} \\
        \pinferty{\uni}{\Gamma, x : A}{B}{\uni[j]}}
      {\inferty{\Gamma}{\P x : A .\ B}{\uni[\umax{i}{j}]}}
    \label{rule:inf-ccw-prod} \and 
    \inferdef{Abs}
      {\pinferty{\uni}{\Gamma}{A}{\uni[i]} \\ \inferty{\Gamma, x : A}{t}{B}}
      {\inferty{\Gamma}{\l x : A .\ t}{\P x : A .\ B}}
    \label{rule:inf-ccw-abs} \and
    \inferdef{App}
      {\pinferty{\Pi}{\Gamma}{t}{\P x : A .\ B} \\ \checkty{\Gamma}{u}{A}}
      {\inferty{\Gamma}{t\ u}{\subs{B}{x}{u}}}
    \label{rule:inf-ccw-app} \\
  \end{mathpar}
  \caption{Rules for inference in bidirectional \kl{CCω}}
  \label{fig:ccw-bidir-infer}
\end{figure}

In anticipation, we set the typing rules for \kl{CCω} so that this transformation would be
directly applicable. This particularly applies to the undirected \ruleref{rule:cic-abs},
recalled opposite.
\marginnote{
  \normalsize
  \begin{mathpar}
  \inferrule*[vcenter,right=Abs]
  {\Gamma \vdash A \ty \uni \\ \Gamma, x : A \vdash t \ty B}
  {\Gamma \vdash \l x : A.\ t \ty \P x : A.\ B}
  \end{mathpar}
}
Indeed, there are at least two other ways to write this rule, which do not lead to a valid
bidirectional presentation.
The first, which is the usual one in \kl{PTS},
is to have $\Gamma \vdash \P x : A.\ B \ty \uni$ instead of simply $\Gamma \vdash A \ty \uni$.
In the setting of a general \kl{PTS}, this is needed, because not every Π-type is well-formed,
even if the domain and codomain are.%
\sidenote{\kl{PTS} where this is true are called \intro{full}.}
However, this premise is problematic in the bidirectional setting. Indeed, $B$ can only be
inferred as a type for the body of the abstraction $t$. But to infer a type for $t$, the
context $\Gamma, x : A$ needs to be well-formed, which is not know if this premise is
the first one.
This issue has been identified by \sidetextcite{Pollack1992}, who remarks that the
bidirectional structure we present here only is equivalent to the undirected one
in semi-full \kl{PTS} – a slight generalization of the full ones.
In a full \kl{PTS}, the opposite approach of simply removing the first premise altogether
can also be taken, relying on \kl{validity} to ensure that $\vdash \Gamma, x \ty A$ and thus
$\Gamma \vdash A : \uni$. But again, in a bidirectional setting, this is not valid, because
it does not respect McBride’s discipline.

The main difference between the bidirectional and undirected rules is that we dropped
hypotheses of context well-formedness in Rules~\nameref{rule:inf-ccw-sort} and \nameref{rule:inf-ccw-var}. Indeed, as the context is always supposed to be well-formed
as an input to the conclusion, it is not useful to re-check it. This is also in line with implementations, where the context is not re-checked at leaves of a derivation tree, with performance issues in mind. The well-formedness invariants then ensure that any derivation starting with the (well-formed) empty context will only ever encounter well-formed contexts.

\subsection{Computation rules}

\begin{marginfigure}
\ContinuedFloat
\begin{mathpar}
  \inferdef{Check}
    {\inferty{\Gamma}{t}{T'} \\ T' \conv T}
    {\checkty{\Gamma}{t}{T}}
  \label{rule:ccw-bidir-check} \and
  \inferdef{Sort-Inf}
    {\inferty{\Gamma}{t}{T} \\ T \fred \uni[i]}
    {\pinferty{\uni}{\Gamma}{t}{\uni[i]}}
    \label{rule:ccw-sort-inf} \and
  \inferdef{Prod-Inf}
    {\inferty{\Gamma}{t}{T} \\ T \fred \P x : A. B}
    {\pinferty{\P}{\Gamma}{t}{\P x : A . B}}
    \label{rule:ccw-prod-inf}
\end{mathpar}
\caption{Computation rules}
\end{marginfigure}

We are left with the only non-structural rule, \ruleref{rule:cic-conv}.
As we observed, there are two possible modes for premises of inference rules where some
constraint is present, leading to the use of either checking or constrained inference.
In turn, this leads to two different modes for computation.
If the target type is an input, it can be compared to the inferred one using \kl{conversion}.
But if it is unknown (constrained inference) we must resort to \kl{reduction},
and obtain it from the inferred one.
This eventually leads to the decomposition of \ruleref{rule:cic-conv} into
\ruleref{rule:ccw-bidir-check} in the first case, while
\nameref{rule:ccw-prod-inf} and \nameref{rule:ccw-sort-inf} correspond to the second case.

\subsection{Constrained inference in disguise}

This need to split the conversion rule into a reduction and conversion sub-routine depending on the mode is of course known to the implementors of proof assistants \sidecite{Abel2011}.
It explains in part the ubiquity of \kl(red){weak-head} reduction
in the dependently typed setting.
Indeed, it is exactly the minimal reduction strategy that is needed to expose the
head constructor of a type, and thus to implement constrained inference.

Still, reduction is only a means to determine whether a certain term fits into a certain category of types. In the setting of \kl{CCω}, this is basically the only way to do.
However, as soon as conversion is extended,
% for instance with unification
% \sidecite{Asperti2012}, coercions \sidecite{Asperti2012,Sozeau2007}
% or graduality \sidecite{LennonBertrand2022},
reduction is often not enough any more.
Putting constrained inference forward explains some ideas required in those: 
they are not ad-hoc workaround, but are based on the need to account for constrained inference.

We already mentioned \sidetextcite{Pollack1992}, where $\Gamma \vdash t \ty T$ is used
for inference, and a judgement written $\Gamma \vdash t \mathrel{:\geq} T$ –
denoting type inference followed by reduction –
is used to effectively inline the two hypothesis of our constrained inference rules.
Checking is also inlined.
Similarly, \sidetextcite{Abel2008} use a judgement written $\Delta \vdash V \delta \Uparrow \operatorname{Set} \rightsquigarrow i$, where a type $V$ is checked to be well-formed, but with its exact level $i$ free. This corresponds very closely to our use of $\pity{\uni}$.

But the main area where constrained inference repeatedly becomes apparent is that of
elaboration. For instance,
\sidetextcite{Saibi1997} describes an elaboration mechanism inserting coercions between types.
This happens primarily during checking, when both types are known.
However, \citeauthor{Saibi1997} introduces two special classes to handle the need
to cast a term to a sort or a function type without more information,
exactly in the places where we resort to constrained inference instead of checking.
More recently, \sidetextcite{Sozeau2007} describes a system where conversion is augmented
to handle coercion between subset types.
As in \textcite{Pollack1992}, $\Gamma \vdash t \ty T$ is used for inference,
and the other judgements are inlined.
Once again, reduction is not enough to perform constrained inference, this time
because type constructors can be hidden in subsets:
a type such as $\{f : \Nat \to \Nat \mid f\ 0 = 0 \}$
should be usable as a function of type $\Nat \to \Nat$.
An erasure procedure is therefore required on top of reduction to remove subset types in the places where we use constrained inference.

Analogous ideas can also be found in Matita's elaboration algorithms 
\sidecite{Asperti2012}.
Indeed, the presence of unification meta-variables on top of coercions makes it
even clearer that specific treatment of what we identified as constrained inference is
required.
\citeauthor{Asperti2012} introduce a special judgement they call
type-level enforcing, which corresponds to our $\pity{\uni}$ judgement.
As for $\pity{\P}$, they have two rules to apply a function, one where its inferred type reduces to a product, corresponding to \ruleref{rule:ccw-prod-inf}.
and another one to handle the case when the inferred type instead reduces to a meta-variable.
As \citeauthor{Saibi1997} and \citeauthor{Sozeau2007}, they also
need to handle coercions for terms in function position. However, their solution is different:
They introduce new meta-variables for the domain and codomain, and rely on unification, which is available in their setting, to find values for those.
For $\pity{\uni}$, though, this solution is not viable, as one would need a kind of universe
meta-variable. Instead, they rely on backtracking to test multiple possible universe choices.

Finally, in \arefpart{gradual}, somewhat akin to the use of meta-variables in
\textcite{Asperti2012}, there are two rules per constrained inference judgement.
One when the head constructor is the desired one – as for \kl{CCω} –,
and a second one to handle the wildcard $\?$, characteristic of gradual type systems.


\section{Properties of the Bidirectional System}
\label{sec:bidir-prop}

\begin{itemize}
  \item Correctness
  \item Completeness
  \item Reduction strategies and uniqueness
  \item Strengthening
\end{itemize}
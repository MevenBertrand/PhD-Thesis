\chapter{Warm-up: CCω}
\label{chap:bidir-ccw}

\margintoc

% In this chapter, we give an alternate presentation of \kl{CCω}, as defined in
% \cref{fig:ccw-typing}. Most of the ideas are abstract over the notion of \kl{conversion}
% that is considered,
% so either \kl(conv){declarative} or \kl(conv){algorithmic} conversion can be used without
% much impact.

\section{Turning \kl(tit){CCω} Bidirectional}
\label{sec:bidir-ccw}

\subsection{McBride’s discipline}
\label{sec:bidir-mcbride}

\AP To design our bidirectional type system, we follow a discipline exposed by McBride
\sidecite[1em]{McBride2018,McBride2019}.
The central point is to distinguish in a judgement between three \intro{modes}:
the \reintro{subject},
whose well-formation is under examination, \reintro{inputs},
whose well-formation is a condition for the judgement to be meaningful,
and \reintro{outputs}, whose well-formation should be a consequence of the judgement.
By \intro{well-formed}, which we use indistinctly for contexts, terms and types,
we mean:
\begin{itemize}
  \item $\vdash \Gamma$ in the case of a context $\Gamma$,
  \item $\Gamma \vdash T \ty \uni$ in the case of a type $T$,
  \item the existence of some $T$ such that $\Gamma \vdash t \ty T$ in the case of a term $t$.
\end{itemize}
For the last two, this is relative to an implicit context $\Gamma$.
We also use \reintro{well-typed} for a term, with the same meaning as \kl{well-formed}.

\AP In the case of \intro{inference} $\intro*\inferty{\Gamma}{t}{T}$, the subject is $t$,
$\Gamma$ is an input and $T$ is an output.
On the contrary, in \intro{checking} $\intro*\checkty{\Gamma}{t}{T}$, $t$ is still the subject
and $\Gamma$ is an input, but this time $T$ is an input as well.
This means that one should consider whether $\inferty{\Gamma}{t}{T}$
only in cases where $\vdash \Gamma$ is already known,
and if the judgement is derivable it should be possible to conclude that
not only $t$, but also $T$ are well-formed.

In order to enforce this property globally, all inference rules should locally
preserve it as an invariant.%
\sidenote{The motto – slightly adapted from \textcite{McBride2018} – is:
  \textit{A rule is a server for its conclusion and a client for its premises.
  Servers receive promises about inputs and make promises about outputs, clients make
  promises about inputs and receive promises about outputs.}}
More precisely, information flows in a clockwise manner. First, we can assume that inputs
to the conclusion are well-formed, as inputs to the whole rule. Next, we move to the
premises. Here the constraint is reversed: we should ensure that inputs to a premise are
well-formed, but can assume that its outputs and subjects are. We might need to use
the well-formation of subjects or outputs of previous ones for that.
Finally, information goes to the conclusion again, and now not only the subject but also
the output should be well-formed if all those of the premises are.

\begin{figure*}
  \begin{mathpar}
  % \inferrule[(1)]
  %   {\phantom{\Gamma \vdash t \pity{\P} \P x : A. B}}
  %   {\Gamma \vdash \tikzmarkin{s1} t\ u \tikzmarkend{s1} \ity \phantom{\subs{B}{x}{u}}} \and
  \inferrule[(1)]
    {\tikzmarkin[ch]{p2}\Gamma \tikzmarkend{p2} \vdash
      \tikzmarkin[uc]{p23} t \pity{\P} \P x : A. B \tikzmarkend{p23}\\
      \tikzmarkin[ch]{p21}\Gamma\tikzmarkend{p21} \vdash
      \tikzmarkin[uc]{p22} u \cty A\tikzmarkend{p22}}
    {\tikzmarkin[ch]{c2}\Gamma\tikzmarkend{c2} \vdash
      \tikzmarkin[uc]{c21}t\ u \ity \subs{B}{x}{u}\tikzmarkend{c21}} \and
  \inferrule[(2)]
  {\tikzmarkin[ch]{p3}\Gamma \vdash t \pity{\P} \P x : A. B \tikzmarkend{p3}\\
    \tikzmarkin[ch]{p31}\Gamma\tikzmarkend{p31} \vdash
    \tikzmarkin[uc]{p32} u \cty A\tikzmarkend{p32}}
  {\tikzmarkin[ch]{c3}\Gamma\tikzmarkend{c3} \vdash
    \tikzmarkin[uc]{c31}t\ u \ity \subs{B}{x}{u}\tikzmarkend{c31}} \and
  \inferrule[(3)]
  {\tikzmarkin[ch]{p4}\Gamma \vdash t \pity{\P} \P x : A. B \tikzmarkend{p4}\\
    \tikzmarkin[ch]{p41}\Gamma\tikzmarkend{p41} \vdash
    \tikzmarkin[uc]{p42} u \tikzmarkend{p42} \cty \tikzmarkin[ch]{p43}A\tikzmarkend{p43}}
  {\tikzmarkin[ch]{c4}\Gamma\tikzmarkend{c4} \vdash
    \tikzmarkin[uc]{c41}t\ u \ity \subs{B}{x}{u}\tikzmarkend{c41}} \and
  \inferrule[(4)]
  {\tikzmarkin[ch]{p5}\Gamma \vdash t \pity{\P} \P x : A. B \tikzmarkend{p5}\\
    \tikzmarkin[ch]{p51}\Gamma \vdash u \cty A\tikzmarkend{p51}}
  {\tikzmarkin[ch]{c5}\Gamma\tikzmarkend{c5} \vdash
    \tikzmarkin[uc]{c51}t\ u \ity \subs{B}{x}{u}\tikzmarkend{c51}} \and
  \inferrule[(5)]
  {\tikzmarkin[ch]{p6}\Gamma \vdash t \pity{\P} \P x : A. B \tikzmarkend{p6}\\
    \tikzmarkin[ch]{p61}\Gamma \vdash u \cty A\tikzmarkend{p61}}
  {\tikzmarkin[ch]{c6}\Gamma \vdash t\ u \ity \subs{B}{x}{u}\tikzmarkend{c6}}
  \end{mathpar}
  \caption{An illustration of McBride’s discipline (well-formed objects are in blue, those not known to be so are in red)}
  \label{fig:bidir-mcbride}
\end{figure*}

As an illustration, an example of a rule that respects this discipline – that
for application – is given in \cref{fig:bidir-mcbride}.
Let us ignore for an instant the exact meaning of the judgement $\mathord{\pity{\P}}$
which we introduce soon, and whose modes are the same as inference.
Instead, focus on well-formation: objects known to be well-formed
are on a blue background, those which are not are on a red one.
First, $\Gamma$ is well-formed, as an input to the conclusion (1). Thus
we can thus move to the first premise, since its only input is $\Gamma$.
From that premise holding, we learn that $t$ and $\P x : A.\ B$ are well-formed (2).
Therefore, $A$ is in particular well-formed, and we can move to the second premise
whose two inputs are now known to be well-formed (3). From it, we learn
that $u$ is well-formed (4). Now we can deduce that $t\ u$ is well-formed. But this is
not enough: since $\subs{B}{x}{u}$ is an output of the conclusion,
we must ensure it is well-formed too. Fortunately,
it is, since $\P x : A.\ B$ is, so $B$ is too,%
\sidenote{In the extended context $\Gamma, x : A$.}
and so $\subs{B}{x}{u}$ is as well, since $\Gamma \vdash u \cty A$.
Thus, we can move back to the conclusion (5), which ends our roundtrip.

A somewhat similar discipline has appeared independently in
\sidetextcite[][Section 4]{Dunfield2021}, where it is called ”Pfenning’s recipe”.
The main criterion is \emph{mode-correctness}, which demands
an information flow similar to McBride’s, but is coarser, as it does not
consider well-formation of the objects, only their knowledge. For instance,
in the case of $\l x : A.\ t$, that criterion allows to directly extend a context
with $A$ to infer a type for $t$, because it is known,
but McBride’s discipline forbids it, because $A$’s well-formation is not established.
Another related condition is also used in \sidetextcite{Bauer2020}.
The authors introduce the notions of a \emph{(weakly) presuppositive type theory}
\cite[Def.~5.6]{Bauer2020} and of \emph{well-presented} premise-family and rule-boundary
\cite[Def.~6.16 and 6.17]{Bauer2020}, using what they call the \intro{boundary} of a judgement
as the analogue of our \kl{inputs} and \kl{outputs}.
Due to their setting being undirected, this is however more restrictive,
because they are not able to distinguish inputs from outputs and thus cannot relax the
condition to only demand inputs to be well-formed but not outputs.

\AP Because of our dependently typed setting, we actually need to introduce a third judgement,
beyond the already mentioned \kl{inference} and \kl{checking}:
\intro{constrained inference}, written
$\intro*\pinferty{h}{\Gamma}{t}{T}$, where $h$ is either $\Pi$ or $\uni$.%
\sidenote{These are the only type formers in \kl{CCω}, but
in \kl{PCUIC}, $h$ can also be \eg an inductive type.}
Constrained inference is a judgement%
\sidenote{Or, rather, a family of judgements indexed by $h$.}
with the exact same \kl{modes} as \kl{inference},
but where the type output is not completely free.
Rather, as the name suggests, a constraint is imposed on it, namely that its head constructor can only be the corresponding element of $h$.
This is needed to handle the behaviour absent in simple types that some terms might not have a desired type “on the nose”. Take for instance the first premise
$\Gamma \vdash t \ty \P x : A .\ B$ of \ruleref{rule:cic-app}.
What bidirectional judgement should replace it?
It would be too much to ask $t$ to directly infer a Π-type, as some reduction might be needed to uncover this $\P$. Checking also cannot be used, because the domain and codomain of the tentative Π-type are not known at that point: they should be inferred from $t$.

Finally, this mode distinction also applies to computation-related judgements,
although those have no subject.
Instead, what is under scrutiny is the “computational content” of the rule.
For conversion $\Gamma \vdash T \conv T' : \uni$, 
both $T$ and $T'$ are inputs and thus should be known to be well-formed beforehand.
For reduction $T \red T'$, on the contrary, $T$ is an input,
but $T'$ is an output. Hence, only $T$ needs to be well-formed \textit{a priori},
and we rely on the \kl{subject reduction} property to ensure
that the output $T'$ also is.

\subsection{The typing rules}

To transform the rules of \kl{CCω} as given in \cref{fig:ccw-typing}, 
start by recalling that we wish to obtain a complete bidirectional type system.
Therefore, any term should infer a type, and thus
all rules where the subject of the conclusion starts with a term former
should give rise to a rule with \kl{inference} as a conclusion.
It thus remains to choose the judgements for the premises,
which amounts to determining their \kl{modes}.
If a term in a premise appears as input in the conclusion or output of a previous premise, then it can be considered an input, otherwise it must be an output. Moreover, if a type output is unconstrained, then \kl{inference} can be used, otherwise we must resort to
\kl{constrained inference}. This transformation leads to the rules of \cref{fig:ccw-bidir-infer}.

\begin{figure}[ht]
  \ContinuedFloat*
  \begin{mathpar}
    \inferdef{Var}
      {(x : T) \in \Gamma}
      {\inferty{\Gamma}{x}{T}}
    \label{rule:bd-var} \and
    \inferdef{Univ}
      { }
      {\inferty{\Gamma}{\uni[i]}{\uni[i+1]}}
    \label{rule:bd-univ} \and
    \inferdef{ΠTy}
      {\pinferty{\uni}{\Gamma}{A}{\uni[i]} \\
        \pinferty{\uni}{\Gamma, x : A}{B}{\uni[j]}}
      {\inferty{\Gamma}{\P x : A .\ B}{\uni[\umax{i}{j}]}}
    \label{rule:bd-prod} \and 
    \inferdef{Abs}
      {\pinferty{\uni}{\Gamma}{A}{\uni[i]} \\ \inferty{\Gamma, x : A}{t}{B}}
      {\inferty{\Gamma}{\l x : A .\ t}{\P x : A .\ B}}
    \label{rule:bd-abs} \and
    \inferdef{App}
      {\pinferty{\Pi}{\Gamma}{t}{\P x : A .\ B} \\ \checkty{\Gamma}{u}{A}}
      {\inferty{\Gamma}{t\ u}{\subs{B}{x}{u}}}
    \label{rule:bd-app} \\
  \end{mathpar}
  \caption{Rules for inference in bidirectional \kl{CCω}}
  \label{fig:ccw-bidir-infer}
\end{figure}

In anticipation, we set the typing rules for \kl{CCω} so that this transformation would be
direct. This particularly applies to the undirected \ruleref{rule:cic-abs},
recalled opposite.
Indeed, there are at least two other ways to write it, which do not lead to a valid
bidirectional presentation.
\marginnote{
  \normalsize
  \begin{mathpar}
  \inferrule*[vcenter,right=Abs]
  {\Gamma \vdash A \ty \uni \\ \Gamma, x : A \vdash t \ty B}
  {\Gamma \vdash \l x : A.\ t \ty \P x : A.\ B}
  \end{mathpar}
}
The first, which is the usual one in \kl{Pure Type Systems} (\kl{PTS})
\sidecite{Barendregt1991},
is to have $\Gamma \vdash \P x : A.\ B \ty \uni$ as a premise
instead of $\Gamma \vdash A \ty \uni$. In the setting of a general \kl{PTS},
this is needed, because not every Π-type is well-formed,
even if the domain and codomain are.%
\sidenote{\kl{PTS} where this is true are called \intro{full}.}
However, this premise is problematic in the bidirectional setting. Indeed, $B$ can only be
inferred as a type for the body of the abstraction $t$. But to infer a type for $t$, the
context $\Gamma, x : A$ needs to be well-formed, which is not known if this premise is
the first one.
This issue has been identified by \sidetextcite{Pollack1992}, who remarked that the
bidirectional structure we present here is only equivalent to the undirected one
in semi-full \kl{PTS} – a slight generalization of the full ones.
In a full \kl{PTS}, the opposite path of simply removing the first premise altogether
can also be taken, relying on \kl{validity} to ensure that $\vdash \Gamma, x \ty A$ and thus
$\Gamma \vdash A : \uni$. But again, in a bidirectional setting,
this does not respect McBride’s discipline.

The main difference between the bidirectional and undirected rules is that we dropped
hypotheses of context well-formation in Rules~\nameref{rule:bd-univ} and
\nameref{rule:bd-var}. Indeed, since the context is always supposed to be well-formed
as an input to the conclusion, it is not useful to re-check it. This is also in line with implementations, where the context is not checked at leaves of a derivation tree, with performance issues in mind. The well-formation invariants then ensure that any derivation starting with the (well-formed) empty context will only ever encounter well-formed contexts.

With the rules for term formers taken care of,
we are left with the single \ruleref{rule:cic-conv}.
\begin{marginfigure}
  \ContinuedFloat
  \begin{mathpar}
    \inferdef{Check}
      {\inferty{\Gamma}{t}{T'} \\ T' \conv T}
      {\checkty{\Gamma}{t}{T}}
    \label{rule:bd-check} \and
    \inferdef{UnivInf}
      {\inferty{\Gamma}{t}{T} \\ T \fred \uni[i]}
      {\pinferty{\uni}{\Gamma}{t}{\uni[i]}}
      \label{rule:bd-pinf-univ} \and
    \inferdef{ΠInf}
      {\inferty{\Gamma}{t}{T} \\ T \fred \P x : A. B}
      {\pinferty{\P}{\Gamma}{t}{\P x : A . B}}
      \label{rule:bd-pinf-prod}
  \end{mathpar}
  \caption{Computation rules for bidirectional \kl{CCω}}
  \label{fig:bidir-ccw-other}
  \end{marginfigure}
There are two different possible adaptations of this rule, depending on
\kl{modes} for computation.
In the case of \kl{checking}, the target type is an input, so
it can be compared to the inferred one using \kl{conversion}.
But in the case of \kl{constrained inference} it is unknown, and so
we must resort to \kl{reduction} to obtain it from the inferred one.
Using \kl{conversion} would not respect modes, since it has two inputs.
This eventually leads to the decomposition of \ruleref{rule:cic-conv} into
\ruleref{rule:bd-check} in the first case, while
\nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod} correspond to the second case.
Note that while the way conversion and reduction can be used in derivations have changed,
those relations themselves remain untouched,
we only refined them by giving them an explicit mode.
We also do not need to choose one or the other notion of \kl{conversion} yet. Instead, we can
stay abstract, only listing the properties we need from it in order to establish the
equivalence.

\subsection{Constrained inference in disguise}

This need to split the conversion rule into a reduction and conversion sub-routines depending on the mode is of course known to the implementors of proof assistants \sidecite{Abel2011}.
It explains in part the ubiquity of \kl(red){weak-head} reduction
in the dependently typed setting.
Indeed, it is exactly the minimal reduction strategy that is needed to expose the
head constructor of a type, and thus to implement constrained inference.

Still, reduction is only a means to determine whether a certain term fits into
a certain kind of types. In the setting of \kl{CCω}, this is basically the only way to do.
However, as soon as conversion is extended or modified,
% for instance with unification
% \sidecite{Asperti2012}, coercions \sidecite{Asperti2012,Sozeau2007}
% or graduality \sidecite{LennonBertrand2022},
reduction is often not enough any more.
Putting constrained inference forward explains some ideas that recurrently appear in
such settings:  they are not ad-hoc workarounds,
but are based on the need to account for constrained inference.

We already mentioned \sidetextcite{Pollack1992}, where $\Gamma \vdash t \ty T$ is used
for inference, and a judgement written $\Gamma \vdash t \mathrel{:\geq} T$ –
denoting type inference followed by reduction –
is used to effectively inline the two hypothesis of our constrained inference rules.
Checking is also inlined.
Similarly, \sidetextcite{Abel2008} use a judgement written $\Delta \vdash V \delta \Uparrow \operatorname{Set} \rightsquigarrow i$, where a type $V$ is checked to be well-formed, but with its exact level $i$ free. This corresponds very closely to our use of $\pity{\uni}$.
\sidetextcite{Gratzer2019} similarly use a judgement $\Xi \vdash T \Leftarrow type$,
but they do not bother inferring the level as they never have any need for it.

But the main area where constrained inference repeatedly becomes apparent is that of
elaboration. For instance,
\sidetextcite{Saibi1997} describes an elaboration mechanism inserting coercions between types.
This happens primarily during checking, when both types are known.
However, \citeauthor{Saibi1997} introduces two special classes to handle the need
to cast a term to a sort or a function type without more information,
exactly in the places where we resort to constrained inference instead of checking.
More recently, \sidetextcite{Sozeau2007} describes a system where conversion is augmented
to handle subset types.
As in \textcite{Pollack1992}, $\Gamma \vdash t \ty T$ is used for inference,
and the other judgements are inlined.
Once again, reduction is not enough to perform constrained inference, this time
because type constructors can be hidden in subsets:
an inhabitant of a type such as $\{f : \Nat \to \Nat \mid f\ \z = \z \}$
should be usable as a function of type $\Nat \to \Nat$.
An erasure procedure is therefore required on top of reduction to remove subsets in the places where we use constrained inference.

Analogous ideas can also be found in \kl{Matita}'s elaboration algorithm, as described in 
\sidetextcite{Asperti2012}.
Indeed, the presence of unification meta-variables on top of coercions makes it
even clearer that a specific treatment of what we identified as constrained inference is
required.
In the case of $\pity{\P}$, they have two rules to apply a function,
one where its inferred type reduces to a Π-type, corresponding to \ruleref{rule:bd-pinf-prod},
and another one to handle the case when the inferred type instead reduces to a meta-variable.
As \citeauthor{Saibi1997} and \citeauthor{Sozeau2007}, they also
need to handle coercions for terms in function position. However, their solution is different:
they introduce new meta-variables for the domain and codomain,
and rely on unification, which is available in their setting, to find values for those.
They also need to introduce a special judgement they call
\intro{type-level enforcing}, which corresponds to our $\pity{\uni}$ judgement.
The solution they take for Π-types is not viable there, as one would need a kind of universe
meta-variable. Instead, they rely on backtracking to test multiple possible universe choices.

Finally, in \arefpart{gradual}, somewhat akin to the use of meta-variables in
\textcite{Asperti2012}, there are two rules per constrained inference judgement.
One when the head constructor is the desired one – as for \kl{CCω} –,
and a second one to handle the wildcard $\?$, characteristic of gradual type systems.


\section{Properties of the Bidirectional System}
\label{sec:bidir-prop}

Let us now state and sketch proofs of the main properties of the bidirectional system.
The first two relate it to the
undirected one: it is both \kl(bidir){sound} – terms typeable in the bidirectional system are typeable in the undirected system – and \kl(bidir){complete} – all terms typeable in the undirected system are also typeable in the bidirectional system.
Next, we investigate \kl{uniqueness of types}, and its relation to the choice of a strategy for reduction.
Finally, we expose how \kl{strengthening} can be shown for undirected \kl{CCω}
by proving it on the bidirectional side.

\subsection{Soundness}

A bidirectional derivation can be seen as a refinement of an undirected derivation.
Indeed, the bidirectional structure can be erased to obtain an undirected derivation, 
replacing each bidirectional rule with the corresponding undirected rule.
As bidirectional rules lack some premises of the undirected ones, missing some sub-derivations
must be retrieved by relying on the well-formation invariants going with McBride’s discipline.
Thus, we get the following soundness theorem – note how the
discipline manifests as well-formation hypothesis on inputs.

\begin{minipage}{\textwidth}
\begin{theorem}[\intro{Soundness} of bidirectional typing for \kl{CCω}]
  \label{thm:corr-ccomega}
  If $\Gamma$ is well-formed and $\inferty{\Gamma}{t}{T}$ or $\pinferty{h}{\Gamma}{t}{T}$,
  then $\Gamma \vdash t \ty T$.
  If both $\Gamma$ and $T$ are well-formed and
  $\checkty{\Gamma}{t}{T}$, then $\Gamma \vdash t \ty T$. 
\end{theorem}  
\end{minipage}

  
\begin{minipage}{\textwidth}
\begin{proof}
  By mutual induction on the bidirectional typing derivation.

  Each rule of the bidirectional system can be replaced by the corresponding rule of the
  undirected system, with all three rules \nameref{rule:bd-check}, \nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod} replaced by
  \nameref{rule:cic-conv}. In all cases, the induction hypothesis can be used on sub-derivations of the bidirectional judgement, because context extensions and checking are
  done with types that are known to be well-formed,%
  \sidenote{This is the point where following McBride’s discipline is crucial!}
  by induction hypothesis on previous premises and possibly \kl{validity}.

  Some sub-derivations of the undirected rules that have no counterpart
  in the bidirectional ones are however missing.
  In Rules \nameref{rule:cic-univ} and \nameref{rule:cic-var},
  the hypothesis that $\Gamma$ is well-formed is enough to get the required premise.
  For \ruleref{rule:bd-check},
  the well-formation hypothesis on the type is needed to get the typing premise of
  \nameref{rule:cic-conv-unty}.
  As for Rules \nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod},
  that typing premise is obtained by combining the induction hypothesis,
  validity and \kl{subject reduction}.

  Alternatively, the appeal to validity could be removed by
  strengthening the theorem to incorporate the well-formation of outputs on top of that of
  the subject. Here we follow the proofs in \kl{MetaCoq}, which establishes
  meta-theoretical properties of the undirected system first – including validity –,
  so we can exploit these.
\end{proof}
\end{minipage}

\subsection{Completeness}

Contrarily to soundness, which keeps the structure of a derivation,
completeness is of a different nature.
Because in bidirectional derivations the computation rules are much less liberal than in
undirected ones, the structure of derivations must be altered.
The crux of the proof is thus to ensure that all uses of \ruleref{rule:cic-conv}
can be permuted down through the other rules,
in order to concentrate them in the places where they are authorized in the bidirectional
derivation.
In a way, composing completeness with soundness gives a kind of normalization procedure
on undirected derivations, which produces a canonical one by pushing conversion
down as much as possible.

The proof mainly relies on the following lemma,
which can be seen as a strong form of \kl{injectivity of type constructors} – 
the version of \cref{prop:prod-inj} is a direct consequence.

\begin{lemma}[Conversion implies reduction for type constructors]
  \label{lem:conv-red-tycons}
  If $T \conv \uni[i]$, then $T \red \uni[i]$.

  If $T \conv \P x : A.\ B$, then there exist $A'$ and $B'$ such that:
  \begin{itemize}
    \item $T \red \P x : A'.\ B'$
    \item $A' \conv A$
    \item $B' \conv B$
  \end{itemize}
\end{lemma}

\begin{minipage}{\textwidth}
\begin{proof}
  Let us spell out the proof on Π-types – the case of $\uni$ is similar, but easier.

  For \kl{algorithmic conversion}, by definition there must exist $T'$ and $T''$
  such that $T \red T'$, $\P x : A.\ B \red T''$, $T' \alpheq T''$.
  But there can be no \kl(red){top-level} reduction step in $\P x : A.\ B \red T''$,
  so actually $T''$ is some $\P x : A''.\ B''$ and $A \red A''$, $B \red B''$.
  Similarly, $T'$ must be some $\P x : A'.\ B'$
  such that $A' \alpheq A''$ and $B' \alpheq B''$.
  Combining these, we obtain that $A' \conv A$ and $B' \conv B$, as expected.

  For \kl{declarative conversion}, we can go through the
  equivalence with algorithmic conversion – and thus use \kl{confluence} under
  the hood.
\end{proof}  
\end{minipage}


\begin{theorem}[\intro{Completeness} of bidirectional typing for \kl{CCω}]
  \label{thm:compl-ccomega}
  If $\Gamma \vdash t \ty T$, then there exists $T'$ such that $\inferty{\Gamma}{t}{T'}$
  and $T' \conv T$.
\end{theorem}

\begin{proof}
  By induction on the undirected typing derivation.
  
  Rules \nameref{rule:cic-var} and \nameref{rule:cic-univ} are base cases,
  and can be simply replaced by the corresponding bidirectional rules.
  In the case of \ruleref{rule:cic-conv}, the property is a direct consequence of the induction hypothesis, together with transitivity of conversion:
  we simply conflate two conversions together.
  
  As for \ruleref{rule:cic-prod}, the induction hypothesis on the domain $A$
  gives the existence of $T_A$
  such that $\inferty{\Gamma}{A}{T_A}$ and $T_A \conv \uni[i]$. Using
  \cref{lem:conv-red-tycons}, we can derive $\pinferty{\uni}{\Gamma}{A}{\uni[i]}$.
  Applying a similar reasoning on the codomain and combining both is enough to conclude.

  In \ruleref{rule:cic-abs}, we do the same reasoning again on the type annotation.
  Combined with the induction hypothesis on the body $t$,
  we get $\inferty{\Gamma}{\l x : A.\ t}{\P x : A .\ B'}$ for some $B'$ such that $B \conv B'$, and thus $\P x : A . B \conv \P x : A . B'$ as desired.

  We are finally left with \ruleref{rule:cic-app}.
  Again, the key is \cref{lem:conv-red-tycons}, which can be combined with the induction
  hypothesis on the function $f$ to get $\pinferty{\P}{\Gamma}{f}{\P x : A' .\ B'}$
  for some $A'$ and $B'$ such that $A \conv A'$ and $B \conv B'$,
  where $\P x : A. B$ is the type of $f$ in the undirected derivation.
  The induction hypothesis on the argument $u$ gives
  $\inferty{\Gamma}{u}{A''}$ with $A'' \conv A$. Thus, by transitivity of conversion
  $\checkty{\Gamma}{u}{A'}$, and we can apply \ruleref{rule:bd-app} to conclude.
\end{proof}

Interestingly, the proof of soundness relies on \kl{subject reduction}, which itself
needs \kl{injectivity of type constructors} and transitivity of conversion.
Similarly, completeness relies both on the injectivity as given by \cref{lem:conv-red-tycons},
and transitivity of conversion. Be it for algorithmic or declarative conversion, one at
least of those is not directly provable – we need \kl{confluence}.
We already hit this same tension between injectivity and transitivity 
with \kl{subject reduction}, and
must draw the same conclusion: there is no free lunch!

\Cref{thm:compl-ccomega} is quite specific to our \kl{Church-style} design.
Instead, an important portion of the research on bidirectional typing in the context
of dependent types adopts a \kl{Curry-style} approach.
This is the case of \eg \sidetextcite{Coquand1996}, the type system of \kl{Agda} as described
by \sidetextcite{Norell2007}, and most of the work by Abel
\sidecite{Abel2007,Abel2008,Abel2011,Abel2017},
and McBride \sidecite{McBride2016,McBride2018,McBride2019}.
In such systems, λ-abstractions can only be checked against a given type, but cannot infer one,
which implies that only terms with no redexes are typeable.
\textcite{Norell2007} argues that explicit
redexes are uncommon in real-life programs, so that being unable to type them is not a strong
limitation in practice. Another solution, taken by \textcite{McBride2022}, is to add
type annotations in order regain the ability to check non-normal terms,
at the cost of inserting annotations at the right place.
In all cases, however, the fact that all terms well-typed in the declarative system infer
a type is irremediably lost. Weaker forms of completeness should still hold for such systems,
typically one where all terms check against their type, but are not ensured to infer.
See for instance \sidetextcite[][Theorem~7.3]{Gratzer2019} for one restricted to normal forms
– and thus not taking the role of annotations into account.

\begin{marginfigure}
  \begin{mathpar} 
    \inferrule
    {T \hred \P x : A' . B \\ \pinferty{\uni}{\Gamma}{A}{\uni[i]} \\
    A \conv A' \\ \checkty{\Gamma, x : A}{t}{B}}
    {\checkty{\Gamma}{\l x : A.\ t}{T}}
  \end{mathpar}  
\end{marginfigure}

In a setting with \kl{Church-style} abstraction,
if one wishes to give the possibility for seemingly untyped abstraction,
another mechanism has to be resorted to, typically elaboration using meta-variables.
This is described in \eg \textcite{Asperti2012},
which combines a rule similar to \ruleref{rule:bd-abs}
– where the type of an abstraction is inferred – with another one,
similar to the \kl{Curry-style} one – where abstraction is checked, see opposite.
While such a rule would make a system as that we have just described “over-complete”,
it is a useful addition to enable the propagation of checking information
upwards in the derivation, which is crucial in elaboration phases, even in \kl{Church-style}.

\subsection{Uniqueness}

All the bidirectional judgements of \cref{fig:ccw-bidir-infer} are syntax-directed,
in the sense that there is always at most one rule that applies to derive a certain typing judgement, given a fixed \kl{subject}.
But there is still some indeterminacy.
Indeed, in rules involving reduction no strategy is fixed, thus two different reducts can be used with the same rule, resulting in different inferred types.
However, inferred types are still related:

\begin{theorem}[Uniqueness of inferred type up to joinability]
  \label{thm:unique-inf}
  If $\Gamma$ is well-formed,
  $\inferty{\Gamma}{t}{T}$ and $\inferty{\Gamma}{t}{T'}$ then $T$ and $T'$ both reduce to a
  common $T''$, \eg $T \red T''$ and $T \red T''$.
  In particular, $T \conv T'$.
\end{theorem}

\begin{proof}
  By mutual induction on the first derivation, together with the same property for
  constrained inference.

  The main idea is to use \kl{confluence} to relate different reduction paths in Rules
  \nameref{rule:bd-pinf-prod} and \nameref{rule:bd-pinf-univ}. For the other rules,
  the conclusion is direct from the induction hypotheses.
\end{proof}

Combining this with \kl(bidir){soundness} and \kl(bidir){completeness},
we get \kl{uniqueness of types} for the undirected system.

\begin{theorem}[Uniqueness of types]
  \label{thm:unique-undir}
  If $\Gamma \vdash t \ty T$ and $\Gamma \vdash t \ty S$ then $T \conv S$.
\end{theorem}

\begin{minipage}{\textwidth}
\begin{proof}
  Since $\Gamma \vdash t \ty T$, by soundness
  there exists some $T'$ such that $\inferty{\Gamma}{t}{T'}$ and moreover $T' \conv T$.
  Similarly, there exists some $S'$ such that $\inferty{\Gamma}{t}{S'}$
  and moreover $S' \conv S$.
  But by uniqueness $T' \conv S'$, and thus $T \conv S$.
\end{proof}  
\end{minipage}


\begin{marginfigure}
\begin{mathpar}
  \inferdef{UnivWhInf}
    {\inferty{\Gamma}{t}{T} \\ T \hred \uni[i]}
    {\pinferty{\uni}{\Gamma}{t}{\uni[i]}}
    \label{rule:bd-pinf-wh-univ} \and
  \inferdef{ΠWhInf}
    {\inferty{\Gamma}{t}{T} \\ T \hred \P x : A. B}
    {\pinferty{\P}{\Gamma}{t}{\P x : A . B}}
    \label{rule:bd-pinf-wh-prod}
\end{mathpar}
\caption{Constrained inference with a weak-head strategy}
\label{fig:wh-pinf}
\end{marginfigure}

In order to completely eliminate indeterminacy, a reduction strategy can be fixed.
This amounts to replacing \kl{full reduction} with \kl{weak-head reduction},
\eg to replace the two reduction rules in \cref{fig:bidir-ccw-other} by those of
\cref{fig:wh-pinf}.
This is still \kl(bidir){sound} and \kl(bidir){complete}.
Soundness follows exactly the same proof as
\cref{thm:corr-ccomega}. As for completeness, the main point is to show an analogous
to \cref{lem:conv-red-tycons} for weak-head reduction.
  
\begin{theorem}[Reduction strategy]
  \label{thm:red-strat}

  If Rules \nameref{rule:bd-pinf-univ} and \nameref{rule:bd-pinf-prod} are replaced by
  \nameref{rule:bd-pinf-wh-univ} and \nameref{rule:bd-pinf-wh-prod},
  then given a well-formed context $\Gamma$ and a term $t$ there is at most one $T$
  such that $\inferty{\Gamma}{t}{T}$, and at most one $T'$ such that
  $\pinferty{h}{\Gamma}{t}{T'}$.
\end{theorem}

\begin{proof}
  Once again, by mutual induction.

  For inference, given a fixed term $t$ there is always at most one rule which applies to
  derive $\inferty{\Gamma}{t}{T}$, since there is exactly one rule per term former.
  Combining this with the uniqueness of types inferred in the premises by induction
  hypothesis is enough to conclude.

  For the constrained inference judgement, once again there is only one rule that applies.
  Since weak-head reduction is deterministic – given $T$, there is at most one $T'$ such that
  $T \hored T'$ –, there is at most one weak-head normal form $\uni$ or $\P x : A.\ B$ for
  a type. Hence, the type obtained by constrained inference is unique.
\end{proof}

\subsection{Strengthening}

Reasoning on the bidirectional derivation makes proofs easier,
while \kl(bidir){soundness} and \kl(bidir){completeness} ensure the results
can be carried to the undirected system.
One way to understand this is that the canonical derivation obtained by combining
soundness and completeness is more structured, and thus more amenable to proofs.

An example of this is the \kl{strengthening} property, a consequence of
\kl{conditional stability under renaming}. We explained in \cref{sec:tech-properties}
why proving these in the undirected system is not straightforward: the issue is that 
computation is too unconstrained, so that derivations might make use of needless variables.
Bidirectional typing, however, does not have this defect, since no type is ever "invented".
Rather, they are obtained either by reduction of previously inferred types, or as inputs.
This means that types in a bidirectional derivation never mention useless variables, and thus
that the following holds.

\begin{minipage}{\textwidth}
\begin{theorem}[Conditional stability under renaming – bidirectional]
  \label{thm:strong-stab-renaming-bidir}
  Whenever we have 
  \begin{itemize}
    \item $\inferty{x_1 : A_1 \dots x_n : A_n}{t}{T}$
    \item for all $i$ such that $x_i$ appears in $t$,
      there is a variable $y_i$ such that $(y_i : \multisubs{A_i}{x_1 \into y_1 \dots x_n \into y_n}) \in \Delta$
  \end{itemize} 
  it also holds that $\inferty{\Delta}{\multisubs{t}{x_1 \into y_1 \dots x_n \into y_n}}{\multisubs{T}{x_1 \into y_1 \dots x_n \into y_n}}$.
\end{theorem}
\end{minipage}

\begin{proof}
  By a direct induction on the typing derivation.

  Note that we do not even need $\Delta$ to be well-formed.
\end{proof}

And as a special case, \kl{strengthening} follows.

\begin{theorem}[Strengthening – bidirectional]
  \label{thm:strengthening-bidir}
  Whenever $\inferty{\Gamma, x : A}{t}{T}$ and $x$ does not appear in $t$,
  $\inferty{\Gamma}{t}{T}$ is derivable.
\end{theorem}

From those, \kl{conditional stability under renaming} and \kl{strengthening} for
the undirected system can be obtained without any difficulty.